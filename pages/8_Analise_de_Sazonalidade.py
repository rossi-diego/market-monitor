# ============================================================
# An√°lise de Sazonalidade - Padr√µes em Contratos Futuros
# ============================================================
"""
An√°lise profissional de sazonalidade em contratos futuros de commodities.
Identifica padr√µes hist√≥ricos e oportunidades de trading baseadas em estat√≠sticas.
"""

# ============================================================
# Imports & Config
# ============================================================
import pandas as pd
import numpy as np
import streamlit as st
import plotly.graph_objects as go
from plotly.subplots import make_subplots

try:
    from scipy import stats
    HAS_SCIPY = True
except ImportError:
    HAS_SCIPY = False

from src.data_pipeline import df as BASE_DF
from src.utils import apply_theme, date_range_picker, section
from src.asset_config import categorized_asset_picker

# Apply theme
apply_theme()

# Page header
st.markdown("# üìÖ An√°lise de Sazonalidade")
st.markdown("Identifique padr√µes sazonais hist√≥ricos em contratos futuros e encontre oportunidades de trading baseadas em estat√≠sticas")
st.divider()

# ============================================================
# Helper Functions
# ============================================================
@st.cache_data
def calculate_returns_by_period(df: pd.DataFrame, asset_col: str, period_type: str) -> pd.DataFrame:
    """
    Calcula retornos di√°rios e agrupa por per√≠odo (m√™s, dia do ano, etc).

    Args:
        df: DataFrame com coluna 'date' e ativo
        asset_col: Nome da coluna do ativo
        period_type: 'month', 'dayofyear', 'weekofyear'

    Returns:
        DataFrame com estat√≠sticas por per√≠odo
    """
    # Prepare data
    df_work = df[['date', asset_col]].copy()
    df_work['date'] = pd.to_datetime(df_work['date'])
    df_work = df_work.dropna().sort_values('date')

    # Calculate daily returns
    df_work['return'] = df_work[asset_col].pct_change() * 100
    df_work = df_work.dropna(subset=['return'])

    # Add period columns
    df_work['year'] = df_work['date'].dt.year
    df_work['month'] = df_work['date'].dt.month
    df_work['dayofyear'] = df_work['date'].dt.dayofyear
    df_work['weekofyear'] = df_work['date'].dt.isocalendar().week

    # Group by period
    grouped = df_work.groupby(period_type)['return']

    # Calculate statistics
    stats_df = pd.DataFrame({
        'periodo': grouped.apply(lambda x: x.name).index,
        'retorno_medio': grouped.mean(),
        'retorno_mediano': grouped.median(),
        'desvio_padrao': grouped.std(),
        'minimo': grouped.min(),
        'maximo': grouped.max(),
        'observacoes': grouped.count(),
    }).reset_index(drop=True)

    # Calculate hit rate (% of positive returns)
    stats_df['taxa_acerto'] = df_work.groupby(period_type)['return'].apply(
        lambda x: (x > 0).sum() / len(x) * 100 if len(x) > 0 else 0
    ).values

    # Calculate Sharpe-like ratio (mean / std)
    stats_df['sharpe_like'] = np.where(
        stats_df['desvio_padrao'] > 0,
        stats_df['retorno_medio'] / stats_df['desvio_padrao'],
        0
    )

    # Statistical significance (t-test against zero)
    if HAS_SCIPY:
        p_values = []
        for period_val in stats_df['periodo']:
            period_returns = df_work[df_work[period_type] == period_val]['return'].values
            if len(period_returns) > 2:
                _, p_val = stats.ttest_1samp(period_returns, 0)
                p_values.append(p_val)
            else:
                p_values.append(1.0)
        stats_df['p_valor'] = p_values
        stats_df['significante'] = stats_df['p_valor'] < 0.05

    # Filter periods with minimum observations
    stats_df = stats_df[stats_df['observacoes'] >= 10].copy()

    return stats_df


def get_period_label(period_type: str, period_val: int) -> str:
    """Retorna label amig√°vel para o per√≠odo."""
    if period_type == 'month':
        meses = ['', 'Jan', 'Fev', 'Mar', 'Abr', 'Mai', 'Jun',
                 'Jul', 'Ago', 'Set', 'Out', 'Nov', 'Dez']
        return meses[int(period_val)]
    elif period_type == 'weekofyear':
        return f"Sem {int(period_val)}"
    elif period_type == 'dayofyear':
        return f"Dia {int(period_val)}"
    return str(int(period_val))


# ============================================================
# Sidebar - Configuration
# ============================================================
with st.sidebar:
    section("Configura√ß√£o", "Par√¢metros da an√°lise", "‚öôÔ∏è")

    # Asset selection using the standard picker
    st.markdown("### Ativo")
    asset_col, asset_label = categorized_asset_picker(
        BASE_DF,
        state_key="seasonality_asset",
        show_favorites=True
    )

    # Period selection
    st.markdown("### Per√≠odo Hist√≥rico")
    start_date, end_date = date_range_picker(
        BASE_DF['date'],
        state_key="seasonality_range",
        default_days=365 * 5  # 5 years default
    )

    # Granularity
    st.markdown("### Granularidade")
    granularity = st.radio(
        "Agrupar por",
        options=['month', 'weekofyear', 'dayofyear'],
        format_func=lambda x: {
            'month': 'üìÖ M√™s do Ano',
            'weekofyear': 'üìÜ Semana do Ano',
            'dayofyear': 'üóìÔ∏è Dia do Ano'
        }[x],
        help="Como agrupar os dados hist√≥ricos para an√°lise de sazonalidade"
    )

    granularity_label = {
        'month': 'M√™s',
        'weekofyear': 'Semana',
        'dayofyear': 'Dia'
    }[granularity]

# ============================================================
# Filter data
# ============================================================
BASE_DF['date'] = pd.to_datetime(BASE_DF['date'], errors='coerce')
mask = (BASE_DF['date'].dt.date >= start_date) & (BASE_DF['date'].dt.date <= end_date)
df_filtered = BASE_DF[mask].copy()

if df_filtered.empty or asset_col not in df_filtered.columns:
    st.error(f"‚ùå Sem dados dispon√≠veis para {asset_label} no per√≠odo selecionado.")
    st.stop()

# Remove NaN values
df_filtered = df_filtered[['date', asset_col]].dropna()

if len(df_filtered) < 30:
    st.warning("‚ö†Ô∏è Dados insuficientes para an√°lise de sazonalidade. Selecione um per√≠odo maior.")
    st.stop()

# ============================================================
# Calculate seasonality statistics
# ============================================================
with st.spinner("Calculando padr√µes de sazonalidade..."):
    seasonality_stats = calculate_returns_by_period(df_filtered, asset_col, granularity)

if seasonality_stats.empty:
    st.warning("‚ö†Ô∏è N√£o foi poss√≠vel calcular estat√≠sticas de sazonalidade. Tente outro per√≠odo ou ativo.")
    st.stop()

# ============================================================
# KPIs Summary
# ============================================================
st.markdown("## üìä Resumo da An√°lise")

with st.container(border=True):
    col1, col2, col3, col4, col5 = st.columns(5)

    # Best period
    best_idx = seasonality_stats['sharpe_like'].idxmax()
    best_period = seasonality_stats.loc[best_idx]

    with col1:
        st.metric(
            "Melhor Per√≠odo",
            get_period_label(granularity, best_period['periodo']),
            f"{best_period['retorno_medio']:.2f}%",
            help=f"Per√≠odo com melhor retorno ajustado por risco (Sharpe-like: {best_period['sharpe_like']:.2f})"
        )

    # Worst period
    worst_idx = seasonality_stats['sharpe_like'].idxmin()
    worst_period = seasonality_stats.loc[worst_idx]

    with col2:
        st.metric(
            "Pior Per√≠odo",
            get_period_label(granularity, worst_period['periodo']),
            f"{worst_period['retorno_medio']:.2f}%",
            help=f"Per√≠odo com pior retorno ajustado por risco (Sharpe-like: {worst_period['sharpe_like']:.2f})"
        )

    # Average hit rate
    avg_hit_rate = seasonality_stats['taxa_acerto'].mean()
    hit_color = "üü¢" if avg_hit_rate > 55 else "üü°" if avg_hit_rate > 50 else "üî¥"

    with col3:
        st.metric(
            "Taxa de Acerto M√©dia",
            f"{avg_hit_rate:.1f}%",
            f"{hit_color}",
            help="% m√©dio de dias com retorno positivo em cada per√≠odo"
        )

    # Most consistent period (high hit rate, low std)
    seasonality_stats['consistencia'] = seasonality_stats['taxa_acerto'] / (seasonality_stats['desvio_padrao'] + 0.01)
    consistent_idx = seasonality_stats['consistencia'].idxmax()
    consistent_period = seasonality_stats.loc[consistent_idx]

    with col4:
        st.metric(
            "Per√≠odo Mais Consistente",
            get_period_label(granularity, consistent_period['periodo']),
            f"{consistent_period['taxa_acerto']:.0f}% acerto",
            help=f"Per√≠odo com maior taxa de acerto e menor volatilidade (std: {consistent_period['desvio_padrao']:.2f}%)"
        )

    # Total observations
    total_obs = seasonality_stats['observacoes'].sum()

    with col5:
        st.metric(
            "Total de Observa√ß√µes",
            f"{total_obs:,}",
            help=f"{len(seasonality_stats)} per√≠odos analisados"
        )

st.divider()

# ============================================================
# Main Chart - Seasonality Pattern
# ============================================================
st.markdown(f"## üìà Padr√£o de Sazonalidade - Retorno M√©dio por {granularity_label}")

with st.container(border=True):
    fig = make_subplots(
        rows=2, cols=1,
        row_heights=[0.65, 0.35],
        subplot_titles=(
            f"Retorno M√©dio Di√°rio por {granularity_label}",
            "Taxa de Acerto (%)"
        ),
        vertical_spacing=0.12
    )

    # Upper panel - Mean return
    fig.add_trace(
        go.Scatter(
            x=seasonality_stats['periodo'],
            y=seasonality_stats['retorno_medio'],
            mode='lines+markers',
            name='Retorno M√©dio',
            line=dict(color='#1f77b4', width=2),
            marker=dict(size=6),
            hovertemplate='%{x}: %{y:.2f}%<extra></extra>'
        ),
        row=1, col=1
    )

    # Confidence bands (¬±1 std)
    upper_band = seasonality_stats['retorno_medio'] + seasonality_stats['desvio_padrao']
    lower_band = seasonality_stats['retorno_medio'] - seasonality_stats['desvio_padrao']

    fig.add_trace(
        go.Scatter(
            x=seasonality_stats['periodo'],
            y=upper_band,
            mode='lines',
            line=dict(width=0),
            showlegend=False,
            hoverinfo='skip'
        ),
        row=1, col=1
    )

    fig.add_trace(
        go.Scatter(
            x=seasonality_stats['periodo'],
            y=lower_band,
            mode='lines',
            line=dict(width=0),
            fillcolor='rgba(31, 119, 180, 0.15)',
            fill='tonexty',
            name='¬±1 Desvio Padr√£o',
            hoverinfo='skip'
        ),
        row=1, col=1
    )

    # Zero line
    fig.add_hline(y=0, line_dash="dash", line_color="gray", opacity=0.3, row=1, col=1)

    # Highlight statistically significant periods
    if HAS_SCIPY and 'significante' in seasonality_stats.columns:
        sig_periods = seasonality_stats[seasonality_stats['significante']]
        if not sig_periods.empty:
            fig.add_trace(
                go.Scatter(
                    x=sig_periods['periodo'],
                    y=sig_periods['retorno_medio'],
                    mode='markers',
                    name='Estatisticamente Significante',
                    marker=dict(
                        size=10,
                        color='red',
                        symbol='star',
                        line=dict(color='darkred', width=1)
                    ),
                    hovertemplate='%{x}: %{y:.2f}% (p<0.05)<extra></extra>'
                ),
                row=1, col=1
            )

    # Lower panel - Hit rate
    colors = ['green' if x >= 60 else 'orange' if x >= 50 else 'red'
              for x in seasonality_stats['taxa_acerto']]

    fig.add_trace(
        go.Bar(
            x=seasonality_stats['periodo'],
            y=seasonality_stats['taxa_acerto'],
            marker_color=colors,
            name='Taxa de Acerto',
            hovertemplate='%{x}: %{y:.1f}%<extra></extra>',
            showlegend=False
        ),
        row=2, col=1
    )

    # 50% reference line
    fig.add_hline(y=50, line_dash="dash", line_color="gray", opacity=0.5, row=2, col=1)

    # Update layout
    fig.update_xaxes(title_text=granularity_label, row=2, col=1)
    fig.update_yaxes(title_text="Retorno (%)", row=1, col=1)
    fig.update_yaxes(title_text="Taxa de Acerto (%)", row=2, col=1)

    fig.update_layout(
        height=700,
        hovermode='x unified',
        template='plotly_white',
        showlegend=True,
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1
        )
    )

    st.plotly_chart(fig, use_container_width=True)

    # Explanation
    with st.expander("‚ÑπÔ∏è Como interpretar este gr√°fico"):
        st.markdown(f"""
        ### üìä Componentes do Gr√°fico

        **Painel Superior - Retorno M√©dio:**
        - **Linha azul**: Retorno m√©dio di√°rio (%) para cada {granularity_label.lower()}
        - **Banda cinza**: Intervalo de ¬±1 desvio padr√£o (mostra a volatilidade)
        - **Estrelas vermelhas**: Per√≠odos com retorno estatisticamente significante (p < 0.05)
        - **Linha pontilhada**: Retorno zero (refer√™ncia)

        **Painel Inferior - Taxa de Acerto:**
        - **Verde**: Taxa de acerto ‚â• 60% (per√≠odos consistentemente positivos)
        - **Laranja**: Taxa de acerto 50-60% (per√≠odos neutros/ligeiramente positivos)
        - **Vermelho**: Taxa de acerto < 50% (per√≠odos frequentemente negativos)
        - **Linha pontilhada**: 50% (refer√™ncia - equivalente a aleat√≥rio)

        ### üéØ Como Usar para Trading

        **Buscar Oportunidades:**
        - Per√≠odos com retorno m√©dio positivo + alta taxa de acerto + baixa volatilidade = oportunidades de compra
        - Per√≠odos com retorno m√©dio negativo + baixa taxa de acerto = potenciais oportunidades de venda

        **Avaliar Risco:**
        - Banda larga (¬±1 std) = maior incerteza, retornos mais dispersos
        - Banda estreita = maior previsibilidade

        **Validar Padr√µes:**
        - Estrelas vermelhas indicam que o padr√£o √© estatisticamente robusto (n√£o √© apenas sorte)
        - Mais observa√ß√µes = padr√£o mais confi√°vel
        """)

st.divider()

# ============================================================
# Rankings - Top/Bottom Periods
# ============================================================
st.markdown("## üèÜ Rankings de Per√≠odos")

with st.container(border=True):
    col_rank1, col_rank2 = st.columns(2)

    with col_rank1:
        st.markdown("### üü¢ Top 5 - Melhores Per√≠odos")
        st.caption("Ordenado por retorno ajustado por risco (Sharpe-like)")

        top5 = seasonality_stats.nlargest(5, 'sharpe_like').copy()
        top5['periodo_label'] = top5['periodo'].apply(lambda x: get_period_label(granularity, x))

        display_top5 = top5[[
            'periodo_label', 'retorno_medio', 'taxa_acerto',
            'desvio_padrao', 'sharpe_like', 'observacoes'
        ]].copy()
        display_top5.columns = ['Per√≠odo', 'Ret. M√©dio (%)', 'Tx. Acerto (%)',
                                'Volatilidade (%)', 'Sharpe-like', 'Obs.']

        st.dataframe(
            display_top5.style.format({
                'Ret. M√©dio (%)': '{:.2f}',
                'Tx. Acerto (%)': '{:.1f}',
                'Volatilidade (%)': '{:.2f}',
                'Sharpe-like': '{:.2f}',
                'Obs.': '{:.0f}'
            }).background_gradient(subset=['Sharpe-like'], cmap='RdYlGn', vmin=-1, vmax=1),
            use_container_width=True,
            hide_index=True
        )

        st.caption("üí° **Sharpe-like**: Quanto maior, melhor o retorno ajustado por risco. >0.5 √© bom, >1.0 √© excelente.")

    with col_rank2:
        st.markdown("### üî¥ Bottom 5 - Piores Per√≠odos")
        st.caption("Ordenado por retorno ajustado por risco (Sharpe-like)")

        bottom5 = seasonality_stats.nsmallest(5, 'sharpe_like').copy()
        bottom5['periodo_label'] = bottom5['periodo'].apply(lambda x: get_period_label(granularity, x))

        display_bottom5 = bottom5[[
            'periodo_label', 'retorno_medio', 'taxa_acerto',
            'desvio_padrao', 'sharpe_like', 'observacoes'
        ]].copy()
        display_bottom5.columns = ['Per√≠odo', 'Ret. M√©dio (%)', 'Tx. Acerto (%)',
                                   'Volatilidade (%)', 'Sharpe-like', 'Obs.']

        st.dataframe(
            display_bottom5.style.format({
                'Ret. M√©dio (%)': '{:.2f}',
                'Tx. Acerto (%)': '{:.1f}',
                'Volatilidade (%)': '{:.2f}',
                'Sharpe-like': '{:.2f}',
                'Obs.': '{:.0f}'
            }).background_gradient(subset=['Sharpe-like'], cmap='RdYlGn_r', vmin=-1, vmax=1),
            use_container_width=True,
            hide_index=True
        )

        st.caption("‚ö†Ô∏è Per√≠odos com Sharpe-like negativo t√™m retorno m√©dio negativo ou muito vol√°teis.")

st.divider()

# ============================================================
# Insights Section
# ============================================================
st.markdown("## üí° Insights Acion√°veis")

with st.container(border=True):
    # Generate insights
    insights = []

    # Best opportunity
    best_opp = seasonality_stats[
        (seasonality_stats['retorno_medio'] > 0) &
        (seasonality_stats['taxa_acerto'] > 55)
    ].nlargest(1, 'sharpe_like')

    if not best_opp.empty:
        opp = best_opp.iloc[0]
        insights.append(f"""
        **üéØ Melhor Oportunidade de Compra:**
        O {get_period_label(granularity, opp['periodo'])} apresenta retorno m√©dio de **{opp['retorno_medio']:.2f}%**
        com taxa de acerto de **{opp['taxa_acerto']:.1f}%** (baseado em {int(opp['observacoes'])} observa√ß√µes).
        Sharpe-like: {opp['sharpe_like']:.2f}
        """)

    # Worst period
    worst_opp = seasonality_stats[
        (seasonality_stats['retorno_medio'] < 0) &
        (seasonality_stats['taxa_acerto'] < 45)
    ].nsmallest(1, 'sharpe_like')

    if not worst_opp.empty:
        opp = worst_opp.iloc[0]
        insights.append(f"""
        **‚ö†Ô∏è Per√≠odo Mais Fraco:**
        O {get_period_label(granularity, opp['periodo'])} historicamente apresenta retorno m√©dio de **{opp['retorno_medio']:.2f}%**
        com taxa de acerto de apenas **{opp['taxa_acerto']:.1f}%**.
        Considere evitar posi√ß√µes compradas ou avaliar hedge neste per√≠odo.
        """)

    # Most consistent
    most_consistent = seasonality_stats.nlargest(1, 'consistencia').iloc[0]
    insights.append(f"""
    **‚úÖ Per√≠odo Mais Consistente:**
    O {get_period_label(granularity, most_consistent['periodo'])} combina alta taxa de acerto
    ({most_consistent['taxa_acerto']:.1f}%) com baixa volatilidade ({most_consistent['desvio_padrao']:.2f}%).
    Ideal para estrat√©gias de menor risco.
    """)

    # Volatility insight
    high_vol = seasonality_stats.nlargest(1, 'desvio_padrao').iloc[0]
    insights.append(f"""
    **üìä Per√≠odo Mais Vol√°til:**
    O {get_period_label(granularity, high_vol['periodo'])} tem a maior volatilidade
    ({high_vol['desvio_padrao']:.2f}%), com retornos variando entre {high_vol['minimo']:.2f}% e {high_vol['maximo']:.2f}%.
    Maior potencial de ganho, mas tamb√©m maior risco.
    """)

    # Statistical significance
    if HAS_SCIPY and 'significante' in seasonality_stats.columns:
        sig_count = seasonality_stats['significante'].sum()
        total_count = len(seasonality_stats)
        insights.append(f"""
        **üìà Robustez Estat√≠stica:**
        {sig_count} de {total_count} per√≠odos apresentam retorno estatisticamente significante (p < 0.05).
        Isso indica que **{sig_count/total_count*100:.0f}%** dos padr√µes observados s√£o estatisticamente robustos.
        """)

    # Display insights
    for insight in insights:
        st.info(insight)

st.divider()

# ============================================================
# Detailed Statistics Table
# ============================================================
st.markdown("## üìã Estat√≠sticas Detalhadas")

with st.container(border=True):
    # Prepare display table
    display_stats = seasonality_stats.copy()
    display_stats['periodo_label'] = display_stats['periodo'].apply(
        lambda x: get_period_label(granularity, x)
    )

    display_cols = [
        'periodo_label', 'retorno_medio', 'retorno_mediano', 'desvio_padrao',
        'taxa_acerto', 'sharpe_like', 'minimo', 'maximo', 'observacoes'
    ]

    if HAS_SCIPY and 'p_valor' in display_stats.columns:
        display_cols.append('p_valor')

    display_table = display_stats[display_cols].copy()
    display_table.columns = [
        'Per√≠odo', 'Ret. M√©dio (%)', 'Ret. Mediano (%)', 'Desvio Padr√£o (%)',
        'Taxa Acerto (%)', 'Sharpe-like', 'M√≠n. (%)', 'M√°x. (%)', 'Obs.'
    ] + (['p-valor'] if HAS_SCIPY and 'p_valor' in display_stats.columns else [])

    st.dataframe(
        display_table.style.format({
            'Ret. M√©dio (%)': '{:.2f}',
            'Ret. Mediano (%)': '{:.2f}',
            'Desvio Padr√£o (%)': '{:.2f}',
            'Taxa Acerto (%)': '{:.1f}',
            'Sharpe-like': '{:.2f}',
            'M√≠n. (%)': '{:.2f}',
            'M√°x. (%)': '{:.2f}',
            'Obs.': '{:.0f}',
            'p-valor': '{:.3f}' if HAS_SCIPY else None
        }).background_gradient(subset=['Ret. M√©dio (%)'], cmap='RdYlGn', vmin=-2, vmax=2),
        use_container_width=True,
        hide_index=True,
        height=400
    )

st.divider()

# ============================================================
# Export
# ============================================================
st.markdown("## üì• Exportar Dados")

col_exp1, col_exp2 = st.columns(2)

with col_exp1:
    # Export statistics
    export_stats = seasonality_stats.copy()
    export_stats['periodo_label'] = export_stats['periodo'].apply(
        lambda x: get_period_label(granularity, x)
    )

    csv_data = export_stats.to_csv(index=False).encode('utf-8')
    st.download_button(
        "üì• Baixar Estat√≠sticas (CSV)",
        data=csv_data,
        file_name=f"sazonalidade_{asset_label.replace(' ', '_')}_{granularity}_{start_date}_{end_date}.csv",
        mime="text/csv",
        key="download_stats"
    )

with col_exp2:
    # Export insights as text
    insights_text = f"""AN√ÅLISE DE SAZONALIDADE - {asset_label}
{'='*60}

Per√≠odo: {start_date} a {end_date}
Granularidade: {granularity_label}
Total de Observa√ß√µes: {total_obs:,}

{'='*60}
INSIGHTS ACION√ÅVEIS
{'='*60}

""" + "\n\n".join(insights)

    st.download_button(
        "üì• Baixar Insights (TXT)",
        data=insights_text.encode('utf-8'),
        file_name=f"insights_{asset_label.replace(' ', '_')}_{granularity}_{start_date}_{end_date}.txt",
        mime="text/plain",
        key="download_insights"
    )

# Footer
st.divider()
st.caption(f"""
üìä **Resumo da An√°lise:**
Ativo: {asset_label} | Per√≠odo: {start_date} a {end_date} | Granularidade: {granularity_label} |
Total: {total_obs:,} observa√ß√µes em {len(seasonality_stats)} per√≠odos
""")
