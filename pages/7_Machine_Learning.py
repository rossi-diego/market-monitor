"""
Machine Learning Forecast Page
------------------------------

This page allows the user to:

1. Select an asset (target variable).
2. Choose which dataset columns will be used as FEATURES.
3. Choose number of LAGS (0 to 10).
4. Select ML model (Ridge, Random Forest, XGBoost).
5. View model performance vs actual (historical backtest).
6. Produce OUT-OF-SAMPLE FORECAST for up to 45 future days.

The page also includes explanations for:
- What are lags?
- How the model learns temporal structure.
- What is multi-step forecasting?
- What MAE, RMSE and RÂ² represent.
"""

# ============================================================
# Imports & Setup
# ============================================================
import pandas as pd
import numpy as np
import streamlit as st
from sklearn.linear_model import Ridge
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

try:
    from xgboost import XGBRegressor
    HAS_XGB = True
except ImportError:
    HAS_XGB = False

from src.data_pipeline import df
from src.utils import apply_theme, date_range_picker, section
import plotly.graph_objects as go

# Theme
apply_theme()

# ============================================================
# Base Data
# ============================================================
BASE = df.copy()
BASE["date"] = pd.to_datetime(BASE["date"], errors="coerce")
BASE = BASE.sort_values("date")

# ============================================================
# Header & Explanation
# ============================================================
section(
    "ðŸ”® Machine Learning Forecast",
    "Selecione um ativo, colunas de entrada e gere previsÃµes automÃ¡ticas.",
    "ðŸ¤–"
)

st.markdown("""
### ðŸ“˜ Como funciona o modelo?

**1) Lags:**  
Lags sÃ£o valores histÃ³ricos da prÃ³pria sÃ©rie â€” por exemplo, *close(t-1)*, *close(t-2)*.  
Eles ajudam o modelo a entender *tendÃªncia, momentum e autocorrelaÃ§Ã£o*.

**2) Features externas:**  
VocÃª pode escolher outras colunas (ex.: dÃ³lar, farelo, prÃªmio, palma...)  
para o modelo aprender *relaÃ§Ãµes cruzadas* entre mercados.

**3) Multi-step forecasting:**  
A previsÃ£o de 45 dias Ã© feita **iterativamente**, um dia de cada vez:  
a previsÃ£o do dia seguinte vira entrada do dia posterior.

**4) MÃ©tricas:**
- **MAE** â€” erro mÃ©dio absoluto (em unidades do preÃ§o)  
- **RMSE** â€” dÃ¡ peso maior a erros grandes  
- **RÂ²** â€” medida relativa; pode ser **negativo** quando o modelo piora o baseline simples (mÃ©dia)

---
""")

# ============================================================
# 1. Target asset selection
# ============================================================
section("ðŸŽ¯ Selecione o ativo para prever", None, "ðŸ“ˆ")

valid_cols = [c for c in BASE.columns if c not in ["date"] and BASE[c].dtype != "object"]

target_col = st.selectbox("Escolha o ativo (Target)", valid_cols, index=0)

st.divider()

# ============================================================
# 2. Feature selection
# ============================================================
section("ðŸ§© Selecione as features (variÃ¡veis explicativas)", None, "ðŸ§©")

feature_cols = st.multiselect(
    "Selecione colunas para o modelo aprender",
    options=valid_cols,
    default=[c for c in valid_cols if c != target_col][:3]
)

# At least 1 feature or lag must exist
if len(feature_cols) == 0:
    st.warning("Selecione ao menos uma feature.")
    st.stop()

st.divider()

# ============================================================
# 3. Lag selection
# ============================================================
section("â³ Lags da sÃ©rie", "MÃ¡ximo 10 lags", "â³")

num_lags = st.slider("NÃºmero de lags", min_value=0, max_value=10, value=5, step=1)

st.markdown("""
Pequena explicaÃ§Ã£o:
- **Lag 1** = preÃ§o de ontem  
- **Lag 2** = preÃ§o de anteontem  
- MÃ¡s lags â†’ mais memÃ³ria â†’ risco de overfitting  
""")

st.divider()

# ============================================================
# 4. ML Model selection
# ============================================================
section("ðŸ¤– Modelo de Machine Learning", None, "ðŸ¤–")

models_dict = {
    "Ridge Regression": Ridge(),
    "Random Forest": RandomForestRegressor(n_estimators=500, random_state=42)
}
if HAS_XGB:
    models_dict["XGBoost"] = XGBRegressor(
        n_estimators=600,
        learning_rate=0.05,
        max_depth=6,
        subsample=0.9,
        colsample_bytree=0.9,
        random_state=42
    )

model_label = st.selectbox("Selecione o modelo", list(models_dict.keys()))
model = models_dict[model_label]

st.divider()

# ============================================================
# 5. Prediction horizon
# ============================================================
section("ðŸ“… Horizonte de previsÃ£o", None, "ðŸ“…")

horizon = st.slider(
    "Dias Ã  frente para prever",
    min_value=1,
    max_value=45,
    value=30
)

st.divider()

# ============================================================
# Prepare dataset (lags + features)
# ============================================================
df_ml = BASE[["date", target_col] + feature_cols].copy()

# Generate lag columns
for lag in range(1, num_lags + 1):
    df_ml[f"{target_col}_lag{lag}"] = df_ml[target_col].shift(lag)

# Drop rows with NaN caused by lags
df_ml = df_ml.dropna().reset_index(drop=True)

# Build X, y
X = df_ml.drop(columns=["date", target_col])
y = df_ml[target_col]

# Train-test split (80/20)
split = int(len(df_ml) * 0.80)
X_train, X_test = X.iloc[:split], X.iloc[split:]
y_train, y_test = y.iloc[:split], y.iloc[split:]
dates_test = df_ml["date"].iloc[split:]

# Fit model
model.fit(X_train, y_train)

# Predict on historical test data
pred_test = model.predict(X_test)

# Metrics
mae = mean_absolute_error(y_test, pred_test)
rmse = np.sqrt(mean_squared_error(y_test, pred_test))
r2 = r2_score(y_test, pred_test)

# ============================================================
# Show metrics
# ============================================================
section("ðŸ“Š MÃ©tricas do modelo", None, "ðŸ“Š")

st.write(f"**MAE:** {mae:.3f}")
st.write(f"**RMSE:** {rmse:.3f}")
st.write(f"**RÂ²:** {r2:.3f}")

st.markdown("""
**InterpretaÃ§Ã£o rÃ¡pida:**

- **MAE** â†’ erro mÃ©dio absoluto  
- **RMSE** â†’ penaliza mais erros grandes  
- **RÂ² negativo** â†’ o modelo foi pior que simplesmente prever a MÃ‰DIA  
""")

st.divider()

# ============================================================
# Plot historical performance
# ============================================================
section("ðŸ“ˆ Desempenho histÃ³rico (real vs previsto)", None, "ðŸ“‰")

fig_hist = go.Figure()
fig_hist.add_trace(go.Scatter(x=dates_test, y=y_test, mode="lines", name="Real"))
fig_hist.add_trace(go.Scatter(x=dates_test, y=pred_test, mode="lines", name="Previsto"))
fig_hist.update_layout(title="HistÃ³rico: Real vs Previsto", xaxis_title="Data", yaxis_title=target_col)
st.plotly_chart(fig_hist, use_container_width=True)

st.divider()

# ============================================================
# Multi-step OUT-OF-SAMPLE forecast
# ============================================================
section("ðŸ”® Forecast Futuro", f"Prevendo {horizon} dias Ã  frente", "ðŸ”®")

last_row = df_ml.iloc[-1:].copy()

future_dates = pd.date_range(start=df_ml["date"].iloc[-1] + pd.Timedelta(days=1), periods=horizon)

forecast_values = []

current_row = last_row.drop(columns=["date", target_col])

for _ in range(horizon):
    next_pred = model.predict(current_row)[0]
    forecast_values.append(next_pred)

    # shift lag columns manually
    if num_lags > 0:
        for i in range(num_lags, 1, -1):
            current_row[f"{target_col}_lag{i}"] = current_row[f"{target_col}_lag{i-1}"]
        current_row[f"{target_col}_lag1"] = next_pred

# Plot forecast
fig_f = go.Figure()
fig_f.add_trace(go.Scatter(
    x=future_dates, y=forecast_values, mode="lines+markers", name="Forecast Futuro"
))
fig_f.update_layout(
    title=f"PrevisÃ£o para {target_col} â€“ {horizon} dias",
    xaxis_title="Data",
    yaxis_title=target_col
)
st.plotly_chart(fig_f, use_container_width=True)

